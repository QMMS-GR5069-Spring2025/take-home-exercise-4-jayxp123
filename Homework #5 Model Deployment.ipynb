{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec0c3174-aa2b-45d7-b253-fe5fc01c142f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow mysql-connector-python\n",
    "%pip install mlflow==2.21.3\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import io\n",
    "from pyspark.sql.functions import col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dbfb9ff-f5a5-4465-b1e6-a7ff5793f03a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "resultsDF = spark.read.csv('s3a://columbia-gr5069-main/raw/results.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f8461ba-9ef6-4c31-993e-79ffd671215b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#This section set ups the data in order to smoothly execute my machine learning models. \n",
    "\n",
    "#Setting up variables as one vector of features and target \n",
    "features = ['grid', 'laps', 'milliseconds', 'fastestLapSpeed']\n",
    "target = 'positionOrder'\n",
    "\n",
    "# There is a possiblity of missing values so those will be dropped\n",
    "resultsDF = resultsDF.dropna(subset=features + [target])\n",
    "\n",
    "# \"milliseconds\" and \"fastestLapSpeed\" were seen as strings, so converting them to doubles\n",
    "resultsDF = resultsDF.withColumn(\"milliseconds\", col(\"milliseconds\").cast(\"double\"))\n",
    "resultsDF = resultsDF.withColumn(\"fastestLapSpeed\", col(\"fastestLapSpeed\").cast(\"double\"))\n",
    "\n",
    "# Using the vector assembler, the features are in a single vector\n",
    "vecAssembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "results_vecDF = vecAssembler.transform(resultsDF)\n",
    "\n",
    "# 80/20 split with a seed of 42 for repodublability sake\n",
    "trainDF, testDF = results_vecDF.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54114685-cb9f-4806-9544-6089e87137d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Using a linear regression with ML Flow to predict the target 'positionOrder'.\n",
    "with mlflow.start_run(run_name=\"LinearRegression_Spark\"):\n",
    "\n",
    "    lr = LinearRegression(featuresCol=\"features\", labelCol=target)\n",
    "    lrModel = lr.fit(trainDF)\n",
    "\n",
    "    predLR = lrModel.transform(testDF)\n",
    "\n",
    "    evaluator = RegressionEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    rmse_lr = evaluator.evaluate(predLR)\n",
    "\n",
    "    r2_evaluator = RegressionEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=\"r2\")\n",
    "    r2_lr = r2_evaluator.evaluate(predLR)\n",
    "\n",
    "    # Log model and metrics\n",
    "    mlflow.spark.log_model(lrModel, \"linear_regression_model\")\n",
    "    mlflow.log_metric(\"rmse\", rmse_lr)\n",
    "    mlflow.log_metric(\"r2\", r2_lr)\n",
    "    mlflow.log_param(\"model_type\", \"LinearRegression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01a94c69-1a8a-4b91-a9e6-a8d4ee36e712",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Predicting the target 'positionOrder' with a random forest.\n",
    "with mlflow.start_run(run_name=\"RandomForest_Spark\"):\n",
    "\n",
    "    rf = RandomForestRegressor(featuresCol=\"features\", labelCol=target, numTrees=100, maxDepth=10)\n",
    "    rfModel = rf.fit(trainDF)\n",
    "\n",
    "    predRF = rfModel.transform(testDF)\n",
    "\n",
    "    rmse_rf = evaluator.evaluate(predRF)\n",
    "    r2_rf = r2_evaluator.evaluate(predRF)\n",
    "\n",
    "    # Log model and metrics\n",
    "    mlflow.spark.log_model(rfModel, \"random_forest_model\")\n",
    "    mlflow.log_metric(\"rmse\", rmse_rf)\n",
    "    mlflow.log_metric(\"r2\", r2_rf)\n",
    "    mlflow.log_param(\"model_type\", \"RandomForestRegressor\")\n",
    "    mlflow.log_param(\"numTrees\", 100)\n",
    "    mlflow.log_param(\"maxDepth\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b3ee863-560e-4ff5-98d0-15daf475e301",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Prepare final DataFrames to save into database\n",
    "predLR_final = predLR.select(*features, target, \"prediction\")\n",
    "predRF_final = predRF.select(*features, target, \"prediction\")\n",
    "\n",
    "# Saving predictions to tables\n",
    "predLR_final.write.format('jdbc').options(\n",
    "    url='jdbc:mysql://jwj2123-gr5069.ccqalx6jsr2n.us-east-1.rds.amazonaws.com/gr5069',\n",
    "    driver='com.mysql.jdbc.Driver',\n",
    "    dbtable='lr_model_predictions',\n",
    "    user='admin',\n",
    "    password='12123212!Asd'\n",
    ").mode('overwrite').save()\n",
    "\n",
    "predRF_final.write.format('jdbc').options(\n",
    "    url='jdbc:mysql://jwj2123-gr5069.ccqalx6jsr2n.us-east-1.rds.amazonaws.com/gr5069',\n",
    "    driver='com.mysql.jdbc.Driver',\n",
    "    dbtable='rf_model_predictions',\n",
    "    user='admin',\n",
    "    password='12123212!Asd'\n",
    ").mode('overwrite').save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f820899-d25e-43eb-969f-b46c874b0539",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Here I am just viewing my predicitons to see if it worked\n",
    "# View the Linear Regression predictions\n",
    "spark.read.format(\"jdbc\").option(\"url\", \"jdbc:mysql://jwj2123-gr5069.ccqalx6jsr2n.us-east-1.rds.amazonaws.com/gr5069\") \\\n",
    "    .option(\"driver\", \"com.mysql.jdbc.Driver\") \\\n",
    "    .option(\"dbtable\", \"lr_model_predictions\") \\\n",
    "    .option(\"user\", \"admin\") \\\n",
    "    .option(\"password\", \"12123212!Asd\") \\\n",
    "    .load().display()\n",
    "\n",
    "# View the Random Forest predictions\n",
    "spark.read.format(\"jdbc\").option(\"url\", \"jdbc:mysql://jwj2123-gr5069.ccqalx6jsr2n.us-east-1.rds.amazonaws.com/gr5069\") \\\n",
    "    .option(\"driver\", \"com.mysql.jdbc.Driver\") \\\n",
    "    .option(\"dbtable\", \"rf_model_predictions\") \\\n",
    "    .option(\"user\", \"admin\") \\\n",
    "    .option(\"password\", \"12123212!Asd\") \\\n",
    "    .load().display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Homework #5 Model Deployment",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
